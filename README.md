This repository contains code for our paper "Collective Decision-Making as a Contextual Multi-armed Bandit Problem", as published at ICML 2019. If you use this code in your own research, please cite this paper:

```
@inproceedings{abels2020collective,
  title={Collective Decision-Making as a Contextual Multi-armed Bandit Problem},
  author={Abels, Axel and Lenaerts, Tom and Trianni, Vito and Now{\'e}, Ann},
  booktitle={International Conference on Computational Collective Intelligence},
  pages={113--124},
  year={2020},
  organization={Springer}
}
```


---------------------------------------
#### Abstract
Collective decision-making (CDM) processes – wherein the knowledge of a group of individuals with a common goal must be combined to make optimal decisions – can be formalized within the framework of the deciding with expert advice setting. Traditional approaches to tackle this problem focus on finding appropriate weights for the individuals in the group. In contrast, we propose here meta-CMAB, a meta approach that learns a mapping from expert advice to expected outcomes. In summary, our work reveals that, when trying to make the best choice in a problem with multiple alternatives, meta-CMAB assures that the collective knowledge of experts leads to the best outcome without the need for accurate confidence estimates.
